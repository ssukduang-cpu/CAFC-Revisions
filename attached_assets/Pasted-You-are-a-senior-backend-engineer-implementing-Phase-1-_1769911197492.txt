You are a senior backend engineer implementing “Phase 1 Smartness” for the CAFC Opinion Assistant: (1) Embeddings-based semantic recall as a FALLBACK augmenter and (2) Query Decomposition as a retrieval augmenter. The system is litigation-grade with quote-first generation and strict citation verification. Your #1 objective is to increase recall and completeness WITHOUT changing baseline behavior or degrading legal defensibility.

NON-NEGOTIABLE CONSTRAINTS
1) Do NOT modify or replace any core logic in:
   - doctrine classification
   - Postgres FTS retrieval
   - precedence-aware ranking scorer (authority/gravity/recency)
   - controlling SCOTUS injection
   - quotable passage extraction
   - context build/pruning
   - LLM prompt strategy (quote-first)
   - citation verification (strict + case binding)
   - web search fallback ingestion
2) Baseline behavior must remain identical when Phase 1 flags are OFF.
3) All Phase 1 functionality must be additive, fail-soft, bounded, and behind feature flags that default OFF.
4) If any Phase 1 step errors or exceeds its time budget, silently skip it and continue with baseline results.

PHASE 1 FEATURE FLAGS (DEFAULT OFF)
- SMART_EMBED_RECALL_ENABLED=false
- SMART_QUERY_DECOMPOSE_ENABLED=false

WHEN TO TRIGGER AUGMENTATION (NARROW, SAFE)
Only run Phase 1 augmentation when at least one is true:
- FTS returns fewer than MIN_FTS_RESULTS (default 8)
- Top FTS score is below MIN_TOP_SCORE threshold (choose a conservative value based on existing ts_rank scale)
- Doctrine classifier confidence is low (if available), else omit this trigger
- The user query is clearly multi-issue (heuristic below), but only if SMART_QUERY_DECOMPOSE_ENABLED=true

HARD BOUNDS (TO PREVENT LATENCY/INSTABILITY)
- Total Phase 1 augmentation budget: 500ms per request (configurable)
- Max extra candidates added by augmentation: 50 total
- Max subqueries generated by decomposition: 4
- Augmentation must never increase context token budget; context build stays as-is.

DELIVERABLES
1) Implementation plan (bulleted)
2) Minimal code changes (file-by-file diffs)
3) DB migration(s) if needed (backwards compatible)
4) Tests:
   - golden tests unchanged + must still pass with flags OFF
   - new “Phase 1 eval” harness that measures improvements with flags ON (does NOT affect prod)
5) Explicit list of untouched core components (repeat list in constraints)

ARCHITECTURE REQUIREMENTS

A) QUERY DECOMPOSITION (AUGMENT RETRIEVAL ONLY)
- Implement backend/smart/query_decompose.py with:
  - should_decompose(query: str) -> bool (detect multi-issue queries via simple heuristics)
  - decompose_query(query: str, max_subqueries=4) -> list[str]
- Heuristics (safe, simple):
  - multiple doctrine signals (e.g., "Alice" + "enablement"; "obviousness" + "secondary considerations"; "claim construction" + "extrinsic evidence")
  - conjunction patterns (“and”, “as well as”, “plus”, “along with”) with distinct legal terms
- Output must be short subqueries (no verbose prompt text).
- Integration:
  1) Always run baseline retrieval on original query.
  2) If enabled and triggers fire, run FTS retrieval for each subquery (bounded).
  3) Merge results as candidates; DO NOT alter baseline retrieval ordering.
  4) Pass merged candidates into existing precedence-aware ranking scorer unchanged.

B) EMBEDDINGS FALLBACK (RECALL AUGMENTER ONLY)
- Implement backend/smart/embeddings.py with:
  - embed_text(text: str) -> vector
  - semantic_recall(query: str, k: int) -> list[candidate_ids]
- Storage:
  - If pgvector available, use it; otherwise implement a minimal storage strategy:
    - store embeddings for chunks/pages in a new table page_embeddings(page_id, embedding, model, created_at)
    - keep feature OFF by default if brute-force would be too slow
- Ingestion:
  - Provide a CLI job to create embeddings offline (do not compute embeddings on-demand in request path):
    - python -m backend.smart.build_embeddings --scope pages --limit N
  - If embeddings do not exist for enough pages, semantic recall should return empty and skip.

- Integration logic (safe):
  1) After baseline FTS retrieval, check triggers and SMART_EMBED_RECALL_ENABLED.
  2) If triggered, fetch up to K semantic candidates (bounded, default 30–50).
  3) Convert candidates into the same object type expected by existing ranking pipeline (page/chunk records).
  4) Union with baseline candidates.
  5) Run existing precedence-aware ranking scorer unchanged.
  6) Continue baseline context build + generation + verification unchanged.

- Important: embeddings MUST NOT become a primary retriever. They only add candidates when baseline is thin.

C) TELEMETRY (ADD ONLY; DO NOT BREAK)
- Extend existing telemetry/query_runs to record Phase 1 usage:
  - flags on/off
  - triggered reason(s): thin_results, low_score, multi_issue
  - added_candidates_count
  - augmentation_latency_ms
- Ensure telemetry failures do not affect responses.

D) EVAL HARNESS (NON-PROD)
- Add backend/smart/eval_phase1.py that:
  - Runs a curated set of “hard queries”
  - Executes baseline (flags OFF) and Phase 1 (flags ON)
  - Reports:
    - NOT FOUND rate delta
    - # verified citations delta
    - top-N authoritative case coverage (heuristic: SCOTUS/en banc presence)
    - latency deltas
  - Writes results to a JSON report file.

SAFETY / REGRESSION GUARANTEES
- With both Phase 1 flags OFF:
  - must produce identical outputs as before (golden verify must pass)
- With flags ON:
  - must never decrease verified citation rate for the eval set (or must report where it does)
  - must never exceed hard latency budget; if it would, skip augmentation
- Any exception in Phase 1 code must be caught and treated as “augmentation skipped”.

FILES / TOUCHPOINTS (MINIMIZE)
- Add new modules under backend/smart/
- Add minimal hooks in backend/chat.py to call augmentation ONLY after baseline retrieval and only when enabled
- Do not modify ranking_scorer or verification code.

OUTPUT FORMAT
Return:
1) Plan
2) Diffs by file
3) SQL migrations (if any)
4) How to run:
   - golden verify
   - embeddings build CLI (if implemented)
   - Phase 1 eval harness
5) Untouched core components list

If any dependency (pgvector, embedding model access) is uncertain, implement clean interfaces and keep SMART_EMBED_RECALL_ENABLED default OFF, with clear instructions to enable once embeddings are built.